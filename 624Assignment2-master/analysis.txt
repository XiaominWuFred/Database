Analysis by Xiaomin Wu 
Question (1):
[xiaomwu@heave2 624Assignment2-master]$ make test
+ cxx txn/storage.cc
+ cxx txn/mvcc_storage.cc
+ cxx txn/txn.cc
+ cxx txn/lock_manager.cc
+ cxx txn/txn_processor.cc
+ cxx txn/lock_manager_test.cc
+ ld bin/txn/lock_manager_test
+ cxx txn/txn_processor_test.cc
+ ld bin/txn/txn_processor_test
== bin/txn/lock_manager_test ==
[ LockManagerA_SimpleLocking ] BEGIN
[ LockManagerA_SimpleLocking ] PASS
[ LockManagerA_LocksReleasedOutOfOrder ] BEGIN
[ LockManagerA_LocksReleasedOutOfOrder ] PASS
[ LockManagerB_SimpleLocking ] BEGIN
[ LockManagerB_SimpleLocking ] PASS
[ LockManagerB_LocksReleasedOutOfOrder ] BEGIN
[ LockManagerB_LocksReleasedOutOfOrder ] PASS
== bin/txn/txn_processor_test ==
			    Average Transaction Duration
		0.1ms		1ms		10ms
'Low contention' Read only (5 records)
 Serial   	8869.8		985.714		99.7907	
 Locking A	43848.6		5488.12		597.55	
 Locking B	43288.5		5519.65		587.553	
 OCC      	42883		5611.06		632.693	
 OCC-P    	41379.4		5625.09		582.012	
 MVCC     	41356.5		5359.54		606.078	
'Low contention' Read only (30 records) 
 Serial   	5762.47		917.844		99.1578	
 Locking A	9830.33		5037.47		477.217	
 Locking B	10071.3		5082.51		570.865	
 OCC      	25144.6		5227.11		589.416	
 OCC-P    	24410.3		4897.27		586.488	
 MVCC     	22158.1		4667.42		561.492	
'High contention' Read only (5 records)
 Serial   	8675		985.798		99.7597	
 Locking A	22411		4238.17		502.132	
 Locking B	41325.5		5617.34		553.96	
 OCC      	41353.1		5526.03		565.885	
 OCC-P    	39337		5432.08		526.377	
 MVCC     	40894.5		5597.35		571.867	
'High contention' Read only (30 records)
 Serial   	6041.99		925.727		99.2677	
 Locking A	2980.29		796.327		97.5835	
 Locking B	16791.7		5220.54		585.346	
 OCC      	25876.9		5267.07		590.482	
 OCC-P    	24143.3		4849.51		521.638	
 MVCC     	25966.2		4677.05		625.937	
Low contention read-write (5 records)
 Serial   	7930.07		969.586		99.6641	
 Locking A	34923.6		5307.99		590.273	
 Locking B	36284.5		5414.72		617.176	
 OCC      	39221		5470.34		590.75	
 OCC-P    	36145.5		5538.88		637.667	
 MVCC     	34677.1		5418.65		573.758	
Low contention read-write (10 records)
 Serial   	6754.92		958.846		99.5622	
 Locking A	19979.9		5108.05		585.177	
 Locking B	19809.1		5198.71		597.216	
 OCC      	32420.5		5436.55		608.21	
 OCC-P    	30775		5310.31		517.405	
 MVCC     	29491.1		4931.78		630.568	
High contention read-write (5 records)
 Serial   	8076.77		977.699		99.7556	
 Locking A	20674.2		4213.99		493.096	
 Locking B	21175		4311.15		482.122	
 OCC      	19690.9		2596.75		255.389	
 OCC-P    	20504.3		2797.42		290.06	
 MVCC     	10285		1330.25		136.76	
High contention read-write (10 records)
 Serial   	7046.64		962.066		99.5397	
 Locking A	8282.48		2461.44		298.089	
 Locking B	8790.37		2429.11		277.093	
 OCC      	9043.23		1166.61		148.255	
 OCC-P    	9714.69		1509.47		157.258	
 MVCC     	4709.48		735.101		70.0977	
High contention mixed read only/read-write 
 Serial   	7246.19		1185.62		123.712	
 Locking A	3291.97		1001.16		123.321	
 Locking B	11404.5		4083.41		699.588	
 OCC      	16400.3		3012.85		329.105	
 OCC-P    	17995.6		3414.68		369.847	
 MVCC     	20846.1		5683.61		675.894	

Question (2):
Two reasons for performance changes when using real application to test from using the busy loop to test.
The first reason can be that busy loop assume the application always run in busy way, while the real application may not be very busy all the time, either the user do not need so frequent read and write to dataset as the busy loop assumed, or the real application need long time of data processing on local device after read data from database. Given a certain period to meature the performance, if using the busy loop gives higher throughput in MVCC and OCC than locking, then with real application the thoughput difference might become very tiny, since although MVCC, OCC has higher throughput when applications are busy all the time during the measure period, if application become not always busy, locking with smaller throughput can also finish the same amount of given work within the period, so then the measured throughput become similar. 
The second reason can be that with the busy loop simulation, we assumed the database accessing mode is read-only, read-write or mixed read-only and read-write with certain amount of records that are accessing of one transection, and measured them seperatly. While using the real application to test, the database accessing mode is mix of all types and randomly contain more or less of each parts depending on how the real application work and how user using the real application use it, and the amount of records been accessing same time will vary too. As we can see from the busy loop simulation result, experiments with different accessing modes and amount of records give result very differently, e.g., the MVCC method show best performance in the high contention mixed read only/read-write accessing mode, while MVCC perform worst in the High contention read-write (10 records) accessing mode, MVCC perform not the worst in the High contention read-write (5 records) accessing mode. With real application, the combination of accessing modes, the amount of records be accessing of one transection are all changing during the measurement period, and will not be identical among different experiment. So the simulation result will be unstable if we use the real application to measure the performance relationship of different concurency control schemes. 

Question (3):
Performance difference between locking A and locking B, why? Compare locking B with standard two-phase-locking, when locking B performance better? when opposite? why?
The difference between locking A and locking B is that locking A implement write and read lock all as EXCLUSIVE lock, whilels locking B implement write as EXCLUSIVE and read as SHARED lock, so that transections with read accessing can go in paralell without being blocked by other reads. 

subquestions <1> when does lock A perform better than lock B? why?:
no experiments show obvious higher performance of locking A than locking B. only experiments show locking A and locking B perform similarly, those are: 'Low contention' Read only (5 records); 'Low contention' Read only (30 records); Low contention read-write (5 records); Low contention read-write (10 records); High contention read-write (5 records); High contention read-write (10 records). For low contention read only, since the contention is low, record rarely be accessed same time by more than two txns. Even though here locking A lock every record by EXCLUSIVE lock which will block each reads, while locking B lock each read by SHARED lock, which will not block each reads, the reads under this condition rarely meet the blocks, so the performance for this situation is similar for locking A and locking B. 
For experiments with read-write accessing mode. we can see all experiments with eigher high contention or low contention are giving near performance for locking A and locking B. This is because in the experiment program, the read-write accessing mode is set as a read first followed by a write, and it only need to acquire a write lock before execution. In another work, read-write accessing only need one write lock in the less simple locking B scheme. Both write lock in locking A and locking B are EXCLUSIVE lock, so there will be no performance difference under this situation.  

subquestion  <2> when does lock B perform better than lock A? why?:
Under following experiment conditions, lock B performs significantly better than lock A: 'High contention' Read only (5 records); 'High contention' Read only (30 records); High contention mixed read only/read-write.
The common part of these three experiment condition is that they are involve read-only accessing mode under high contention. Under this condition, reads will be executed highly likely on same record, so that Locking A using EXCLUSIVE lock for both read and write will block each reads, i.e., each read need to wait for other read if they are targeting to the same record. While locking B will not block each read from other reads, since locking B is giving read operation a SHARED lock, which allows more than one reads with SHARED lock to read same record at same time. 

subquestion <3> compare locking B with standard two phase locking, when will lock B perform better and when will standard two phase locking perform better?
As the question mentioned, in locking B, each lock is acquired immediately before it is needed, while in the standard two phase locking, locks are all acquired at the beginning of a transaction. 
In heavy lock contention, the standard two phase locking reduces the time locks are held on average, relative to the locking B, because transactions that hold locks are never blocked.
In light lock contention, the standard two phase locking holds more locks than is necessary, because it is hard to tell what locks will be needed in the future, thus leads to higher overhead, and has worse performance than locking B. 

Question (4): 
subquestion <1>: How did OCC and pOCC compare with each other in this simulation? How do you think that is the case?
OCC and POCC implementation difference is that POCC put the validation part in paralell while OCC do the validation in serial manner. 

In 'Low contention' Read only (5 records), 'Low contention' Read only (30 records), 'High contention' Read only (5 records), 'High contention' Read only (30 records), i.e., in all read-only experiments, OCC performs a little bit better than POCC. This is because under the read-only condition, validation will not fail, since no write operation ever update any records, so when validation in our implementation check if the record is last updated after the current txn's start time, the result will always be false, so the validation will always pass. Under this situation, the validation of OCC is not the big part of executing time, while for the POCC, although POCC put validation in paralell, but POCC has to copy and maintain the active set with critical section and iterate through the active set for every txn's readsets to see if any conflicts are there, although there are no conflicts in fact. As the result, OCC has slightly better throughput than POCC under four read-only experiments. Note that with more records of accessing of each txn, the advantages of OCC will increase, since POCC's overhead in checking active set with current txn's readset writeset intersects will increase.

In read-write case with low contention (10 records), since the contention is low, although write operation are involved, but the validation still has less chance to fail, So the overhead of POCC for copying, maintaining active set in critical section, checking active set with read write set for intersects is the cause for that POCC performs worse than OCC. 

In read-write case with low contention (5 records), this experiment is special with 0.1 ms result OCC>POCC while with 1ms and 10ms result POCC>OCC. My explanation for this case is as following: Here we have records number, contention high or low and transection period plays obvious role in the simulation result. Low contention makes the validation less likely to fail even with write operations involved. 5 records compare to 10 records in above case makes the overhead of operations to active sets smaller. The period of transection's effect is observable under this situation. Since for POCC, validation are put in each paralell thread, after the transaction done validation can immediately start. while the OCC put the all validation for finished transaction in a while loop after assigning all txn in request queue to paralell threads. The outer while loop will only start with available txn in the request queue. based on our simulation program setting, the validation failed txn will be put back to the request queue to restart. And when the outer while loop go to the inner while loop for validation, if there are no txn in the complete txn queue, the inner while loop will not start to do any validation. Any txn finished between the gap will wait for next outer while loop start run (wait for some txn be put back to request queue). So, in this case, when the period of transection increase, the serial validation in OCC will not all be served as quick as those txn are ready to get validation. And when outer loop try to serve validation part, most of txn may not ready to start validation. In this case, POCC although having overhead in paralell validation, but can serve the validation right after each txn get ready for validation, so that performs better than OCC in period of txn equal to 1ms and 10ms cases. Note that the impacts of period of txn for the OCC code structure described above is also true for other experiment cases, while in other experiment cases the effects are not obvious.

In read-write case with high contention and mixed read-only/read-write with high contention, now the validation has high chance to fail with high contention and write operation involved. Now the overhead of POCC's validation becomes less obvious with much bigger amount of work in validation part. And with much bigger amount of work in validation part, the advantage of puting validation in paralell shows out, therefore, the POCC performs better than OCC under this circumstance.

subquestion <2> How does this compare to the OCC paper that we read for class? What is the biggest reason for the difference between your results and the what you expected after reading the OCC paper?

The reading paper for OCC from class believes the POCC should perform better than OCC under a multicore environment. While in our simulation, POCC performs worse than OCC in all read-only case and read-write with low contention case. Also for difference in implementation, the OCC and POCC introduced in the paper records all txns between start of a txn and end of it, and then check if write sets of those txns intersects the read set of the txn under validating, if so, the validation fails. While in this simulation, OCC and POCC implementations are using recording start time for each txn and recording last updating time for each records (the data accessed by current txn). So, the validation becomes checking if the last updating time of all records of this txn are smaller than the txn's starting time, if yes, validation successes, since no other txn modify the records this txn are accessing, if no, validation fails. But for the active set part in POCC, the simulation implementation and the paper's implementation are similar. 

The expectation from reading the paper is that, with multiprocessor environment, paralell validation OCC (POCC) should perform much better than OCC in high contention with write operation involved, and POCC should perform similarly with OCC under low contention with or without write operation involved. While simulation experiments give result not as the expectation. Simulation results show the POCC only perform little bit better than OCC under high contention with write operation involved, and perform little bit worse than OCC under low contention with or without write operation involved. The biggest reason for the difference is that the overhead of copying, maintaining active set in critical section and iteration search for validation with active sets gives much more impacts to the runtime than expected. 

Question(5): OCC vs locking B.
subquestion<1>: what is the reason for OCC suddenly being better for 30-record transactions? 
Two experiments have both read-only accessing mode of txns. under read-only mode, locking B needs to acquire SHARED lock for every records of every txns. Although those SHARED lock never block other read operation, but with the increasing of the amount of records the process of acquiring and releasing those SHARED locks, which need to go through the lock manager logic everytime for every records whenever acquire and realse a lock, are a significant and obvious overhead under other experiments setting (the contention, the read-only or read-write modes) of this two experiments. For OCC, although is under high contention, but validation never fail since no write operation are involved here. OCC validation also has overheads for checking the last modification time of each records with the txn starting time, but under this condition, the overhead of OCC is significantly smaller than Locking B. with the 5 records becomes 30 records, the overhead difference become much more obvious in the overall performance of two concurrency control schemes. 

subquestion<2>: OCC loses to locking B for the 'high contention' read-write test with both 5 and 10 records, why? why does the relative difference between OCC and Locking B get larger for txns longer than 0.1 ms in the 'high contention' read-write test?
From the experiments result, under high contention read-write tests with both 5 and 10 records, OCC performs worse than Locking B and the difference getting more obvious with txns more than 0.1 ms. My explanation to this experiment result is as following: Under high contention read-write operation involved condition, there will be high amount of conflict in the records accessing. For Locking B, it will grant each record EXCLUSIVE lock if it is needed for write operation and SHARED lock if it is needed for read operation, siince the contention is very high, same record will hold many different accessing from different txns, but in the end every accessing will be arranged in a serial order, without wasted executations. While for OCC under this condition, OCC suffers with lots of wasted executations. For every txns failed, they have to be cancelled and start again. Since the contention is high and write operation involved, there will be huge amount of txns failed and needs to start again more than one time. In the end, although OCC parallelly executing transactions, it will execute much more failed tranactions which decrease the throughput much. So although locking B has big overhead in managing locks for each records, but the wasted runing time of OCC here is more significant and make OCC perform worse than Locking B. And the performance difference will become larger with transactions with period more than 0.1ms, since as described above, locking B just put every txns in serial way with every txn run once, but OCC run many times of txns since txns have high chance to fail in the validation part in this case, So OCC run too much redundant txns, and if each txn require more than to run, the OCC will perform much worse than locking B. In short, the increased running time of each txn increases the overall runing time multiple times for OCC, since OCC run each txn not only once, instead multiple times if they keep failing the validation, and Locking B will only increase the amount of txn times each txn's increased runing time, since Locking B arrange every txn in serial order and only run each txn once. 

Question(6): MVCC vs OCC/Locking
subquestion<1>: For the read-write tests, MVCC performs worse than OCC and Locking. Why? It even sometimes does worse than serial. Why?
With the read-write test, the accessing mode plays a great part in the result difference. the read-write accessing mode do a read and followed by a write operation to the same record, it is like to increase a certain record by some value, so a read is performed before a write to the same record. Then our MVCC implementation in this simulation is first get available txn in request queue, and put them into paralell threads to execute the txn and then do version check for determining if the write operations are valid of this txn. MVCC only check write operations to determine if the txn can complete or not. In the write checking part, MVCC abort the txn if any one of the record the txn is trying to write to has the last recent version (version_id is the biggest among all version having version_id smaller than this txn's txn_unique_id) already be read by a newer txn than this txn. This happens in high possibility with the read-write test, since if two or more than two txns happens to operate on same record in database, our MVCC algorithm execute these txns in parallely, if the time used to put txns into paralell threads is less than the executing time of txn's read part, which should always be true unless the txn's period is extremly fast, then the read operation of the second started txn having txn_unique_id 2 will make the first txn with txn_unique_id 1 abort its write operation, since the same record (version_id before txn_unique_id 1) is holding a max_read_id (id number of last txn read this record) as 2 which is bigger than the first txn (txn_unique_id as 1) trying to write this record. Same thing will happen to txn 2 if txn 3 is operating on the same record as txn 2, and same thing will happen for txn n if txn (n-1) is operating on the same record as txn n. Then, in all those paralell executing txns, only the last txn (txn n) can complete without aborting its write operation, and txns before this last txn all need re-run and redo the checkWrite mentioned above. If those failed txn's restart time are very close, then same thing will happens again, only one of them can complete without aborting their write operation. Besides the situation analyzed above, in MVCC, locks are used both for read and checkWrite->applyWrite in order to make sure no newer read is executed on the same record which is under checkWrite and applyWrite when checkWrite finished showing the write is valid and can continue to do the applyWrite but applyWrite is not done yet. In short, to prevent newer read to the record between checkWrite and applyWrite to the same record. Under the read-write test case, read-write operation is read and write on the same record, this increase the chance for checkWrite->applyWrite and read region block each other among different txns. If different txns are targeting on same record, then not only read will block other txns' read, read will also block other txns' checkWrite->applyWrite, and checkWrite->applyWrite not only will block checkWrite->applyWrite of other txns, it will also block reads of other txns. OCC and locking has no such weakness mentioned above as MVCC under read-write tests, OCC only record modification to record done by write operations, do validation to see if any read record is modified after, and locking just arange every write operation in a serial order. OCC and locking do have overhead, but not as big as the overhead of MVCC under most of read-write test case. We can see the experiment result shows the analysis above very well. For all read-write test, high contention with 10 records of each txn gives highest chance for different txns to operate on same record, High contention with 5 records for each txn gives the second highest chance of different txns operating on same record, the following is the Low contention with 10 records for each txn test, and the low contention with 5 records for each test holds the smallest chance for txns to operate on same record among these 4 test conditions. We can see from the results, in high contention 10 records test condition, MVCC performs even worse than SERIAL method, since the MVCC suffers most from the above analyzed two hazards in this test case. And for High contention 5 records, MVCC performs significantly worse than OCC and Locking, but little bit better than SERIAL, since in this case, chance for different txns to operate on same record become smaller with records change from 10 to 5. And in the two low contention cases, MVCC performs slightly worse than OCC and locking in most of results (different combinations with records amount and txn's period time), some results show MVCC is better than locking, like in the low contention read-write 10 records, this is because the situation mentioned above has more less chance to happen in these two cases, and drop down of MVCC becomes less obvious here with other advantages of MVCC like MVCC need not to check the read operations, adds a little overhead to read operations (in our implementation, only the patial serialization of locking before read till read finish for same record), and so that overheads of locking already mentioned in other questions shows more obvious effect to the overall thoughput results under this condition.

subquestion<2>: Yet for the mixed read-only/read-write experiment it performs the best, even though it wasn't the best for either read-only nor read-write. Why?
In the high contention mixed read only/read-write the MVCC get significant better performance than locking and OCC, POCC. While MVCC perform similarly to others in the read-only part. For why MVCC performs worse with read-write part, I already explained in the subquestion<1> part of question(6). I'll explain why locking performs similarly with MVCC in read-only but perform worse than MVCC in high contention mixed read only/read-write first. MVCC in our implementation lock the targeting record before read and unlock the record after read. The same lock to same record is also used before checkWrite till applyWrite finishes. so txns with read-only accessing mode targeting to same records will be executed in serial manner, and also will be blocked by checkWrite and applyWrite. But under read-only test case, no write operation so no checkWrite and applyWrite needed, overhead is only come from the partial serialization of read operations on same records. locking B gives some amount of overhead for read acquiring and releasing, active set copying and maintaining, but not block those reads, reads are run in paralell. So they performs similar in read-only test case when the overhead of locking cost similar with the partially serialized read in MVCC (like low contention read-only 5 records); MVCC performs better than locking when locking's overhead cost more (like low contention 30 records read-only, more records for each txn more overhead of locking). But in mixed read-only/read-write test case, although read operations still count 80% of all operations, the rest 20% write operations will be assigned EXCLUSIVE lock, and those EXCLUSIVE locks will break the continuity of SHARED locks for 80% read operations in Locking B. So that, although 80% read-only operations are there, locking B performs significantly worse than MVCC since Locking B can not fully put all 80% read operations in paralell, they are intersected with EXCLUSIVE locks for write operations. While MVCC still adds small amount of overhead (partial serialization) to read operations, but MVCC only abort txn with invalid write operations, never abort txn with only read operations. So even though there are added 20% write operation in the mixed read-only/read-write test case, MVCC run all read-only txn only once and put most of the read operations in paralell. Note that by partial serialization of read operations of MVCC, I mean MVCC put some read operations accessing the same record in serial by using lock, but in MVCC, there are different records, the chance for different read operations to accesse same record is low in low contention and not as high as 100% in high contention, so the serialization is not like the serilization in SERIAL mode.

Next, for why MVCC performs similarly with OCC and POCC in read-only test cases but performs significantly better in mixed read only/read-write test case, my explanation is as following: OCC don't block read operations but OCC need to check if each record read has been modified by other txns in validation part (OCC need to do validation on read). MVCC blocks read operations targeting to the same record, if records amount is not high and contention is not high, there will not be much read operation in serial. In read-only test cases, the OCC validation always pass, since there is no write operation involved, so this just add some computation overhead. And MVCC has some computation overhead by locking read operation on same record. So if several read operation is reading same record, they will be arranged in serial order. But this happens with very small chance in low contention with low records amount and not as high as 100% in high contention with high records amount, since we have different records in the dataset. so the critical section of read in MVCC didn't gives too much overhead, especially in low contention case. OCC's overhead in validating each read record is similar with MVCC's overhead. So MVCC and OCC performs similarly in read-only test cases. And in the high contention mixed read-only/read-write case, although read-only operations count 80% of total operations, txns with read-only has chance to fail validation if the record they read is modified by other write operation of other txns in OCC. But for read-only operations in MVCC, they will always complete. And only the 20% write operations have chance to restart if some future txn read the record version they are trying to write. And also the hazard explained in Question(6) subquestion<1> will not happen as much as in read-write only situation, since txn with read-only operations seperate those read-write txns, so that txns with only read-write operations will not be put into paralell threads very densely in time line. The advantage of MVCC passing all txn with read-only operations once is very obvious under this test case. Therefore, MVCC performs better than OCC in mixed read-only/read-write test case.


Question(7): Why did our MVCC pseudocode request read locks before each read? In particular, what would happen if you didn't acquire these read locks? How long do these locks have to be held?

Since our implementation of MVCC, each read operation need to update the max_read_id inside the read version (holding biggest version_id among those versions whose version_id are smaller than the unique_txn_id of the txn trying to do the read) to the belonging txn's unique_txn_id to keep track of what txn is the last txn read a certain version of record for the purpose of performing write check later, the write check need to use this max_read_id to see if the last recent version (holding biggest version_id among those versions whose version_id are smaller than the unique_txn_id of the txn trying to do the write) of a record is read by a txn newer than the txn trying to do the write, if this happens, the txn has to abort the write and get rescheduled. The record will also be locked before checkWrite and unlocked after applyWrite. So in the process of checkWrite->applyWrite, no read operation should be executed in between the checkWrite and applyWrite. So locks for the targeted record before read is needed. 
If we don't set the locks to protect the region each read operation do the read and update the max_read_id, then only locks to protect the resion start from checkWrite to the finish of applyWrite are not able to prevent read from executing in between of checkWrite and applyWrite, which will make the checkWrite result wrong, a write was believed valid in the checkWrite time become invalid in the applyWrite time, since a txn with newer version than the txn trying to write read the record version just be checked by the txn trying to write, and then the txn trying write just apply its write without knowing there actually is a txn nerwer than itself read the record version just after it checked it been valid to write. In the end, a invalid write is done. therefore, locks for the targeted record before read is necessary to prevent this hazard.

These locks have to be held till the read operation done and the max_read_id is modified in the record version it read from. In the implementation, I put the lock and unlock before and after each Read operation of MVCC. 


