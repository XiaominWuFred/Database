//******
Xiaomin Wu 
ID: 116091985
HW1 response.txt
//******

1. Brief explanation (between three to four paragraphs):
Qs:
why do some models get higher throughput than other models? 

Which process model is the fastest and why is it the fastest? 

Which one is slowest and why is it slowest? 

Why are the ones in the middle slower/faster than the two at the extremes? 

How and why does throughout change as the maximum number of outstanding requests or pool size change? 

In addition, explain the differences between high-contention and low-contention experiments.

As:
Recall that throughput is defined as requests per second. The process per request model has the lowest throughput with around 30 requests per second for all maximum outstanding request. Each request being executed need to create a process and the process will die after the request is finished executing. Creating and killing processes, which costs a lot of runtime. Process pool model has much higher throughput than process per request model, since process pool model keeps all the processes alive in a pool and make them waiting for incoming requests. In this way, time is saved for creating and killing processes. Thread per request model is also having higher throughput than process per request model. This is because thread per request model does not need to do context switching when changing processes, it only has one process with multiple threads. The process per request model suffers from context switching. Process pool model also has context switching, but since thread per request model needs time for creating and killing thread for each request, the throughput of these two models are close. The thread pool model has the highest throughput among these four models. It avoids the context switching and creating, killing threads comparing to process pool model and thread per request model. Thread pool model holds all threads in a pool and lets those threads wait for new coming requests. As mentioned above, the fastest is the thread pool model, since it does not need to create killing threads for each new request, and do context switching during processes exchange. The slowest is the process per request model because it needs to creating and killing processes for each new request and also needs to do context switching during processes exchanging. Process pool model in the middle slower than the thread pool model, close to the thread per request model, since it needs context switch, but do not need creating and killing process for each new request. thread per request model is faster than process per request model since process per request model needs to do context switch during process exchanging. 
High-contention experiments give much more chance for threads/processes to conflict with each other so that other threads/processes have to suspend to wait for the one thread/process to finish the critical section then go to do the critical section one by one. The Low-contention experiments give much less chance for threads/processes to conflict with each other. In high-contention situation, threads/processes need to wait for the current thread/process doing the critical section (example as the linked list modification section in our assignment). Extra time is needed for the suspending and waking thread/process, extremely hurt for processes, which needs switching security context, memory manager state, file and network handle tables, and other process contex. That is why in high-contension experiments, thread per request model is slightly faster than process pool model, while the opposite in low-contension experiments. 
Throughput changing when the max-outstanding or pool size increases, it is a result of the balance between more requests in 'parallel' and more conflicts to deal with. 'parallel' here means if the program is running with one CPU, the CPU keeps switching threads/processes that looks like all threads/processes are running in parallel, but actually needs switching states and context. While the 'parallel' can accelerate speed is because when a thread/process has to wait, some other thread/process that is ready can run. It is like an optimization situation, when 'parallel' too less, i.e., too less max-outstanding or pool size, the CPU resource is not fully utilized; when too high max-outstanding or pool size, too many conflicts need to deal with. So in the experiment result, for high-contension, the highest throughput is shown from the middle number of max-outstanding and pool size experiments. For low-contension, since the conflict is made very low for low-contension expirements, the increasing max-outstanding and pool size do not increase the conflicts to an obvious impacts, so as more requests put in 'parallel', the throughput of thread per request and thread pool models get increasing without decreasing, since they are less affected by the conflictions. While the process pool model shows the highest throughput in the middle of max-outstanding and pool size value since it is more sensitive to the amount of conflictions involved. But we can see from the result that process pool model in low-contension experiments has the highest throughput with less max-outstanding or pool size than it in high-contension experiments, since in high-contension experiments, the number of conflictions is originally higher than low-contension experiments. 


2. Answer each of the following questions briefly:
Qs:
1) The process-pool implementation must copy a request into a process'
request buffer. The process-per-request implementation, however, does
not need to copy or pass requests between processes. Why?

Process pool's processes are reusing for every new request. Process per thread model kill the old process and create a new process for new coming request. To implement process pool in that way, each process in the pool are implemented as an infinite loop, It communicates with outside using a process state structure. Inside the structure is a pointer to request buffer, so that the process can get a new request from the buffer and start execution. While process per request model forks new process to handle the new request, by just executing the request in the newly forked child process.



2) The process-pool implementation requires a request to be copied
into a process-local buffer before the request can be executed. On the
other hand, the thread-pool implementation can simply use a pointer to
the appropriate request. Why?

Because process pool model involves multiple processes while the thread pool model using only one process with multiple threads. For threads, the input request is saved in the same process with same memory address space and can be reached with a pointer. While for process pool model, different processes are using different memory address space, so when the main process want to pass the incoming request to the processes in the process pool, it need to copy the request's contents from the memory address space of the main process to the memory address space of the process in the process pool.